{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hospital Resource Management - Entity Extraction\n",
    "\n",
    "**Course**: Knowledge Graphs with Large Language Models  \n",
    "**Program**: MSc in AI and Data Science, 2025-2026  \n",
    "**Instructor**: Panos Alexopoulos\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook implements an LLM-based entity extraction system for populating a Hospital Resource Management knowledge graph.\n",
    "\n",
    "**Target Entities:**\n",
    "1. **Equipment** - Medical devices and equipment\n",
    "2. **Department** - Hospital departments and clinical units\n",
    "\n",
    "**Tasks:**\n",
    "- Task 1: Entity Extractor Development\n",
    "- Task 2: Extractor Evaluation - Precision & Recall\n",
    "- Task 3: LLM-as-a-Judge Evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai python-dotenv pandas scikit-learn -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Setup complete\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Tuple\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "print(\"✓ Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Entity Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Extractor functions defined\n"
     ]
    }
   ],
   "source": [
    "def create_extraction_prompt(text: str) -> str:\n",
    "    \"\"\"Create few-shot prompt for entity extraction\"\"\"\n",
    "    return f\"\"\"You are an expert in medical entity extraction for knowledge graph population.\n",
    "\n",
    "Extract two types of entities:\n",
    "1. **Equipment**: Medical devices, diagnostic machines, surgical equipment\n",
    "2. **Department**: Hospital departments and clinical units\n",
    "\n",
    "Rules:\n",
    "- Only extract terms that explicitly appear in the text\n",
    "- Extract exact phrases as they appear\n",
    "- Include variations (e.g., \"MRI\", \"MRI machine\")\n",
    "- Return distinct entities only\n",
    "\n",
    "Example 1:\n",
    "Text: \"The Emergency Department acquired a CT scanner and ventilators. Radiology will operate the CT scanner.\"\n",
    "Output:\n",
    "{{\n",
    "  \"Equipment\": [\"CT scanner\", \"ventilators\"],\n",
    "  \"Department\": [\"Emergency Department\", \"Radiology\"]\n",
    "}}\n",
    "\n",
    "Example 2:\n",
    "Text: \"Cardiology has an advanced MRI machine for cardiac imaging. The ICU needs access to this MRI.\"\n",
    "Output:\n",
    "{{\n",
    "  \"Equipment\": [\"MRI machine\", \"MRI\"],\n",
    "  \"Department\": [\"Cardiology\", \"ICU\"]\n",
    "}}\n",
    "\n",
    "Example 3:\n",
    "Text: \"Surgical robots are being deployed. The Neurology department requested access to the robotic surgery system.\"\n",
    "Output:\n",
    "{{\n",
    "  \"Equipment\": [\"Surgical robots\", \"robotic surgery system\"],\n",
    "  \"Department\": [\"Neurology\"]\n",
    "}}\n",
    "\n",
    "Now extract entities from:\n",
    "Text: \"{text}\"\n",
    "\n",
    "Output (JSON only):\n",
    "\"\"\"\n",
    "\n",
    "def extract_entities(text: str, model: str = \"gpt-4o\") -> Dict[str, List[str]]:\n",
    "    \"\"\"Extract Equipment and Department entities using GPT\"\"\"\n",
    "    prompt = create_extraction_prompt(text)\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a medical entity extraction expert. Respond with valid JSON only.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        \n",
    "        result = json.loads(response.choices[0].message.content)\n",
    "        \n",
    "        if \"Equipment\" not in result:\n",
    "            result[\"Equipment\"] = []\n",
    "        if \"Department\" not in result:\n",
    "            result[\"Department\"] = []\n",
    "        \n",
    "        result[\"Equipment\"] = list(dict.fromkeys(result[\"Equipment\"]))\n",
    "        result[\"Department\"] = list(dict.fromkeys(result[\"Department\"]))\n",
    "        \n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return {\"Equipment\": [], \"Department\": []}\n",
    "\n",
    "print(\"✓ Extractor functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT:\n",
      "The Emergency Department received three new ventilators and an advanced CT scanner. \n",
      "The Cardiology department is coordinating with Radiology to share the new MRI machine. \n",
      "The ICU requested access to portable ultrasound devices.\n",
      "\n",
      "EXTRACTED:\n",
      "Equipment (4): ['ventilators', 'CT scanner', 'MRI machine', 'portable ultrasound devices']\n",
      "Department (4): ['Emergency Department', 'Cardiology', 'Radiology', 'ICU']\n"
     ]
    }
   ],
   "source": [
    "test_text = \"\"\"The Emergency Department received three new ventilators and an advanced CT scanner. \n",
    "The Cardiology department is coordinating with Radiology to share the new MRI machine. \n",
    "The ICU requested access to portable ultrasound devices.\"\"\"\n",
    "\n",
    "result = extract_entities(test_text)\n",
    "\n",
    "print(\"INPUT:\")\n",
    "print(test_text)\n",
    "print(\"\\nEXTRACTED:\")\n",
    "print(f\"Equipment ({len(result['Equipment'])}): {result['Equipment']}\")\n",
    "print(f\"Department ({len(result['Department'])}): {result['Department']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Evaluation functions defined\n"
     ]
    }
   ],
   "source": [
    "def load_evaluation_dataset(filepath: str = \"evaluation_dataset.json\") -> List[Dict]:\n",
    "    \"\"\"Load manually annotated evaluation dataset\"\"\"\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        dataset = json.load(f)\n",
    "    print(f\"✓ Loaded {len(dataset)} texts\")\n",
    "    return dataset\n",
    "\n",
    "def normalize_entity(entity: str) -> str:\n",
    "    \"\"\"Normalize entity for comparison\"\"\"\n",
    "    return entity.lower().strip()\n",
    "\n",
    "def calculate_metrics(predicted: List[str], ground_truth: List[str]) -> Tuple[float, float, float]:\n",
    "    \"\"\"Calculate Precision, Recall, F1\"\"\"\n",
    "    pred_set = set(normalize_entity(e) for e in predicted)\n",
    "    truth_set = set(normalize_entity(e) for e in ground_truth)\n",
    "    \n",
    "    tp = len(pred_set & truth_set)\n",
    "    fp = len(pred_set - truth_set)\n",
    "    fn = len(truth_set - pred_set)\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "    \n",
    "    return precision, recall, f1\n",
    "\n",
    "def evaluate_extractor(dataset: List[Dict]) -> pd.DataFrame:\n",
    "    \"\"\"Evaluate extractor on full dataset\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for item in dataset:\n",
    "        text_id = item['id']\n",
    "        text = item['text']\n",
    "        ground_truth = item['ground_truth']\n",
    "        \n",
    "        print(f\"Processing text {text_id}...\")\n",
    "        predicted = extract_entities(text)\n",
    "        \n",
    "        for entity_type in ['Equipment', 'Department']:\n",
    "            pred = predicted.get(entity_type, [])\n",
    "            truth = ground_truth.get(entity_type, [])\n",
    "            \n",
    "            precision, recall, f1 = calculate_metrics(pred, truth)\n",
    "            \n",
    "            results.append({\n",
    "                'text_id': text_id,\n",
    "                'entity_type': entity_type,\n",
    "                'precision': precision,\n",
    "                'recall': recall,\n",
    "                'f1_score': f1,\n",
    "                'predicted': len(pred),\n",
    "                'ground_truth': len(truth)\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "print(\"✓ Evaluation functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded 12 texts\n",
      "Processing text 1...\n",
      "Processing text 2...\n",
      "Processing text 3...\n",
      "Processing text 4...\n",
      "Processing text 5...\n",
      "Processing text 6...\n",
      "Processing text 7...\n",
      "Processing text 8...\n",
      "Processing text 9...\n",
      "Processing text 10...\n",
      "Processing text 11...\n",
      "Processing text 12...\n",
      "\n",
      "============================================================\n",
      "EVALUATION RESULTS\n",
      "============================================================\n",
      "\n",
      "Overall Performance:\n",
      "  Precision: 0.745\n",
      "  Recall:    0.767\n",
      "  F1 Score:  0.750\n",
      "\n",
      "Per Entity Type:\n",
      "\n",
      "Equipment:\n",
      "  Precision: 0.903\n",
      "  Recall:    0.924\n",
      "  F1 Score:  0.902\n",
      "\n",
      "Department:\n",
      "  Precision: 0.587\n",
      "  Recall:    0.611\n",
      "  F1 Score:  0.597\n",
      "\n",
      "✓ Results saved to evaluation_results.csv\n"
     ]
    }
   ],
   "source": [
    "dataset = load_evaluation_dataset(\"evaluation_dataset.json\")\n",
    "results = evaluate_extractor(dataset)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EVALUATION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nOverall Performance:\")\n",
    "print(f\"  Precision: {results['precision'].mean():.3f}\")\n",
    "print(f\"  Recall:    {results['recall'].mean():.3f}\")\n",
    "print(f\"  F1 Score:  {results['f1_score'].mean():.3f}\")\n",
    "\n",
    "print(\"\\nPer Entity Type:\")\n",
    "for entity_type in ['Equipment', 'Department']:\n",
    "    subset = results[results['entity_type'] == entity_type]\n",
    "    print(f\"\\n{entity_type}:\")\n",
    "    print(f\"  Precision: {subset['precision'].mean():.3f}\")\n",
    "    print(f\"  Recall:    {subset['recall'].mean():.3f}\")\n",
    "    print(f\"  F1 Score:  {subset['f1_score'].mean():.3f}\")\n",
    "\n",
    "results.to_csv(\"evaluation_results.csv\", index=False)\n",
    "print(\"\\n✓ Results saved to evaluation_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detailed Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detailed Results by Text:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>entity_type</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>predicted</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Equipment</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Department</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Equipment</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Department</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Equipment</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>Department</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>Equipment</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>Department</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>Equipment</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>Department</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6</td>\n",
       "      <td>Equipment</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>Department</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7</td>\n",
       "      <td>Equipment</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7</td>\n",
       "      <td>Department</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8</td>\n",
       "      <td>Equipment</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8</td>\n",
       "      <td>Department</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9</td>\n",
       "      <td>Equipment</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9</td>\n",
       "      <td>Department</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10</td>\n",
       "      <td>Equipment</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10</td>\n",
       "      <td>Department</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>11</td>\n",
       "      <td>Equipment</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>11</td>\n",
       "      <td>Department</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>12</td>\n",
       "      <td>Equipment</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>12</td>\n",
       "      <td>Department</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    text_id entity_type  precision    recall  f1_score  predicted  \\\n",
       "0         1   Equipment   1.000000  0.666667  0.800000          2   \n",
       "1         1  Department   0.714286  1.000000  0.833333          7   \n",
       "2         2   Equipment   0.800000  1.000000  0.888889          5   \n",
       "3         2  Department   1.000000  1.000000  1.000000          1   \n",
       "4         3   Equipment   0.600000  1.000000  0.750000         10   \n",
       "5         3  Department   0.333333  0.333333  0.333333          3   \n",
       "6         4   Equipment   1.000000  0.666667  0.800000          2   \n",
       "7         4  Department   0.000000  0.000000  0.000000          0   \n",
       "8         5   Equipment   0.888889  1.000000  0.941176          9   \n",
       "9         5  Department   0.000000  0.000000  0.000000          0   \n",
       "10        6   Equipment   1.000000  1.000000  1.000000          3   \n",
       "11        6  Department   0.000000  0.000000  0.000000          0   \n",
       "12        7   Equipment   0.750000  0.750000  0.750000          4   \n",
       "13        7  Department   1.000000  1.000000  1.000000          2   \n",
       "14        8   Equipment   1.000000  1.000000  1.000000          6   \n",
       "15        8  Department   0.800000  0.800000  0.800000          5   \n",
       "16        9   Equipment   1.000000  1.000000  1.000000          6   \n",
       "17        9  Department   1.000000  1.000000  1.000000          4   \n",
       "18       10   Equipment   0.888889  1.000000  0.941176          9   \n",
       "19       10  Department   1.000000  1.000000  1.000000          5   \n",
       "20       11   Equipment   0.909091  1.000000  0.952381         11   \n",
       "21       11  Department   0.400000  0.400000  0.400000          5   \n",
       "22       12   Equipment   1.000000  1.000000  1.000000          9   \n",
       "23       12  Department   0.800000  0.800000  0.800000          5   \n",
       "\n",
       "    ground_truth  \n",
       "0              3  \n",
       "1              5  \n",
       "2              4  \n",
       "3              1  \n",
       "4              6  \n",
       "5              3  \n",
       "6              3  \n",
       "7              7  \n",
       "8              8  \n",
       "9              5  \n",
       "10             3  \n",
       "11             0  \n",
       "12             4  \n",
       "13             2  \n",
       "14             6  \n",
       "15             5  \n",
       "16             6  \n",
       "17             4  \n",
       "18             8  \n",
       "19             5  \n",
       "20            10  \n",
       "21             5  \n",
       "22             9  \n",
       "23             5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nDetailed Results by Text:\")\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: LLM-as-a-Judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ LLM judge functions defined\n"
     ]
    }
   ],
   "source": [
    "def create_judge_prompt(text: str, extracted: Dict[str, List[str]], entity_type: str) -> str:\n",
    "    \"\"\"Create prompt for LLM judge\"\"\"\n",
    "    entities = extracted.get(entity_type, [])\n",
    "    \n",
    "    descriptions = {\n",
    "        \"Equipment\": \"medical devices, diagnostic machines, surgical equipment\",\n",
    "        \"Department\": \"hospital departments, clinical units, organizational divisions\"\n",
    "    }\n",
    "    \n",
    "    return f\"\"\"You are an expert evaluator for medical entity extraction.\n",
    "\n",
    "Judge if extracted entities are correct. An entity is CORRECT if:\n",
    "1. It appears in the original text\n",
    "2. It belongs to the specified entity type\n",
    "3. It is a valid instance of that type\n",
    "\n",
    "Entity Type: {entity_type} ({descriptions[entity_type]})\n",
    "\n",
    "Original Text:\n",
    "\"{text}\"\n",
    "\n",
    "Extracted {entity_type}:\n",
    "{json.dumps(entities, indent=2)}\n",
    "\n",
    "For each entity, judge:\n",
    "- CORRECT: appears in text and correctly classified\n",
    "- INCORRECT: hallucinated or wrongly classified\n",
    "- PARTIAL: partially correct\n",
    "\n",
    "Output (JSON):\n",
    "{{\n",
    "  \"evaluations\": [\n",
    "    {{\"entity\": \"...\", \"judgment\": \"CORRECT|INCORRECT|PARTIAL\", \"reasoning\": \"...\"}}\n",
    "  ],\n",
    "  \"summary\": {{\n",
    "    \"correct\": <number>,\n",
    "    \"incorrect\": <number>,\n",
    "    \"partial\": <number>\n",
    "  }}\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "def llm_judge(text: str, extracted: Dict[str, List[str]], entity_type: str, model: str = \"gpt-4o\") -> Dict:\n",
    "    \"\"\"Use LLM as judge to evaluate extraction\"\"\"\n",
    "    prompt = create_judge_prompt(text, extracted, entity_type)\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert evaluator. Respond with valid JSON only.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        \n",
    "        return json.loads(response.choices[0].message.content)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return {\"evaluations\": [], \"summary\": {\"correct\": 0, \"incorrect\": 0, \"partial\": 0}}\n",
    "\n",
    "print(\"✓ LLM judge functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test LLM Judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing LLM Judge on Equipment:\n",
      "\n",
      "{\n",
      "  \"evaluations\": [\n",
      "    {\n",
      "      \"entity\": \"ventilators\",\n",
      "      \"judgment\": \"CORRECT\",\n",
      "      \"reasoning\": \"The entity 'ventilators' appears in the original text and is correctly classified as Equipment.\"\n",
      "    },\n",
      "    {\n",
      "      \"entity\": \"CT scanner\",\n",
      "      \"judgment\": \"CORRECT\",\n",
      "      \"reasoning\": \"The entity 'CT scanner' appears in the original text and is correctly classified as Equipment.\"\n",
      "    },\n",
      "    {\n",
      "      \"entity\": \"new equipment\",\n",
      "      \"judgment\": \"PARTIAL\",\n",
      "      \"reasoning\": \"The entity 'new equipment' appears in the original text, but it is a general term and not a specific instance of Equipment. It partially matches the context but lacks specificity.\"\n",
      "    }\n",
      "  ],\n",
      "  \"summary\": {\n",
      "    \"correct\": 2,\n",
      "    \"incorrect\": 0,\n",
      "    \"partial\": 1\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"\"\"The Emergency Department acquired two new ventilators and a CT scanner. \n",
    "The Cardiology team will help train staff on the new equipment.\"\"\"\n",
    "\n",
    "sample_extraction = {\n",
    "    \"Equipment\": [\"ventilators\", \"CT scanner\", \"new equipment\"],\n",
    "    \"Department\": [\"Emergency Department\", \"Cardiology\"]\n",
    "}\n",
    "\n",
    "print(\"Testing LLM Judge on Equipment:\\n\")\n",
    "judge_result = llm_judge(sample_text, sample_extraction, \"Equipment\")\n",
    "print(json.dumps(judge_result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Judge on Sample Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LLM Judge on sample texts:\n",
      "\n",
      "Text 1:\n",
      "Source: UCI Health News - July 2024\n",
      "\n",
      "Equipment:\n",
      "  Correct: 2\n",
      "  Incorrect: 0\n",
      "  Partial: 0\n",
      "Department:\n",
      "  Correct: 6\n",
      "  Incorrect: 0\n",
      "  Partial: 1\n",
      "\n",
      "Text 2:\n",
      "Source: Northwestern Medical Center Press Release - 2024\n",
      "\n",
      "Equipment:\n",
      "  Correct: 4\n",
      "  Incorrect: 1\n",
      "  Partial: 0\n",
      "Department:\n",
      "  Correct: 1\n",
      "  Incorrect: 0\n",
      "  Partial: 0\n",
      "\n",
      "Text 3:\n",
      "Source: UNM Hospital News - February 2024\n",
      "\n",
      "Equipment:\n",
      "  Correct: 9\n",
      "  Incorrect: 1\n",
      "  Partial: 0\n",
      "Department:\n",
      "  Correct: 1\n",
      "  Incorrect: 2\n",
      "  Partial: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate LLM judge on a subset of texts\n",
    "sample_texts = dataset[:3]  # First 3 texts\n",
    "\n",
    "print(\"Evaluating LLM Judge on sample texts:\\n\")\n",
    "\n",
    "for item in sample_texts:\n",
    "    text = item['text']\n",
    "    extracted = extract_entities(text)\n",
    "    \n",
    "    print(f\"Text {item['id']}:\")\n",
    "    print(f\"Source: {item['source']}\\n\")\n",
    "    \n",
    "    for entity_type in ['Equipment', 'Department']:\n",
    "        result = llm_judge(text, extracted, entity_type)\n",
    "        summary = result.get('summary', {})\n",
    "        \n",
    "        print(f\"{entity_type}:\")\n",
    "        print(f\"  Correct: {summary.get('correct', 0)}\")\n",
    "        print(f\"  Incorrect: {summary.get('incorrect', 0)}\")\n",
    "        print(f\"  Partial: {summary.get('partial', 0)}\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook implements:\n",
    "1. **Entity Extractor**: LLM-based extraction using GPT-4o with few-shot prompting\n",
    "2. **Evaluation**: Precision/Recall/F1 metrics on 12 manually annotated real-world texts\n",
    "3. **LLM Judge**: Automated evaluation system for extraction quality assessment\n",
    "\n",
    "Results demonstrate the effectiveness of prompt engineering for medical entity extraction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
